import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd
import re
from nltk.stem import SnowballStemmer
import matplotlib.pyplot as plt

# ğŸ§  ConfiguraciÃ³n inicial
st.set_page_config(page_title="Analizador de Frases ğŸ’¬", page_icon="ğŸ§©", layout="centered")
st.markdown("<h1 style='text-align:center; color:#FF4B4B;'>ğŸ’¡ Analizador de Frases en EspaÃ±ol</h1>", unsafe_allow_html=True)

# Documentos de ejemplo
default_docs = """El perro ladra fuerte en el parque.
El gato maÃºlla suavemente durante la noche.
El perro y el gato juegan juntos en el jardÃ­n.
Los niÃ±os corren y se divierten en el parque.
La mÃºsica suena muy alta en la fiesta.
Los pÃ¡jaros cantan hermosas melodÃ­as al amanecer."""

# Stemmer en espaÃ±ol
stemmer = SnowballStemmer("spanish")

def tokenize_and_stem(text):
    text = text.lower()
    text = re.sub(r'[^a-zÃ¡Ã©Ã­Ã³ÃºÃ¼Ã±\s]', ' ', text)
    tokens = [t for t in text.split() if len(t) > 1]
    stems = [stemmer.stem(t) for t in tokens]
    return stems

# Layout
col1, col2 = st.columns([2, 1])

with col1:
    text_input = st.text_area("ğŸ“ Documentos (uno por lÃ­nea):", default_docs, height=150)
    question = st.text_input("â“ Escribe tu pregunta:", "Â¿DÃ³nde juegan el perro y el gato?")

with col2:
    st.markdown("### ğŸ’¡ Preguntas sugeridas:")
    if st.button("Â¿DÃ³nde juegan el perro y el gato?", use_container_width=True):
        st.session_state.question = "Â¿DÃ³nde juegan el perro y el gato?"
        st.rerun()
    if st.button("Â¿QuÃ© hacen los niÃ±os en el parque?", use_container_width=True):
        st.session_state.question = "Â¿QuÃ© hacen los niÃ±os en el parque?"
        st.rerun()
    if st.button("Â¿CuÃ¡ndo cantan los pÃ¡jaros?", use_container_width=True):
        st.session_state.question = "Â¿CuÃ¡ndo cantan los pÃ¡jaros?"
        st.rerun()
    if st.button("Â¿DÃ³nde suena la mÃºsica alta?", use_container_width=True):
        st.session_state.question = "Â¿DÃ³nde suena la mÃºsica alta?"
        st.rerun()
    if st.button("Â¿QuÃ© animal maÃºlla durante la noche?", use_container_width=True):
        st.session_state.question = "Â¿QuÃ© animal maÃºlla durante la noche?"
        st.rerun()

if 'question' in st.session_state:
    question = st.session_state.question

# ğŸ” AnÃ¡lisis
if st.button("ğŸ” Analizar", type="primary"):
    documents = [d.strip() for d in text_input.split("\n") if d.strip()]
    
    if len(documents) < 1:
        st.error("âš ï¸ Ingresa al menos un documento.")
    elif not question.strip():
        st.error("âš ï¸ Escribe una pregunta.")
    else:
        vectorizer = TfidfVectorizer(tokenizer=tokenize_and_stem, min_df=1)
        X = vectorizer.fit_transform(documents)
        df_tfidf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out(), index=[f"Doc {i+1}" for i in range(len(documents))])
        st.markdown("### ğŸ“Š Matriz TF-IDF")
        st.dataframe(df_tfidf.round(3), use_container_width=True)
        
        # Similitud
        question_vec = vectorizer.transform([question])
        similarities = cosine_similarity(question_vec, X).flatten()
        best_idx = similarities.argmax()
        best_doc = documents[best_idx]
        best_score = similarities[best_idx]
        
        # ğŸ¯ Mensajes dinÃ¡micos
        st.markdown("### ğŸ¯ Resultado del anÃ¡lisis")
        st.markdown(f"**Tu pregunta:** {question}")
        
        if best_score > 0.4:
            st.success(f"âœ¨ Â¡Alta coincidencia! Este documento parece responder muy bien a tu pregunta.\n\n**Respuesta:** {best_doc}")
        elif best_score > 0.2:
            st.warning(f"ğŸ¤” Coincidencia media. PodrÃ­as reformular la pregunta.\n\n**Respuesta:** {best_doc}")
        else:
            st.error(f"ğŸ˜… Coincidencia baja. Tal vez prueba con otras palabras.\n\n**Respuesta:** {best_doc}")
        
        st.info(f"ğŸ“ˆ Similitud: {best_score:.3f}")
        
        # ğŸ”¤ Resaltado de palabras clave coincidentes
        question_tokens = set(tokenize_and_stem(question))
        doc_tokens = set(vectorizer.get_feature_names_out())
        matched_words = question_tokens & doc_tokens
        
        if matched_words:
            st.markdown("### âœ¨ Palabras clave coincidentes:")
            st.markdown(f"<p style='color:#FF4B4B; font-size:18px;'>{', '.join(sorted(matched_words))}</p>", unsafe_allow_html=True)
        else:
            st.markdown("### ğŸ” No se encontraron coincidencias exactas de palabras clave.")
        
              
        # ğŸ“ˆ VisualizaciÃ³n de similitudes
        st.markdown("### ğŸ“‰ Nivel de similitud por documento")
        plt.barh([f"Doc {i+1}" for i in range(len(documents))], similarities, color="#FF4B4B")
        plt.xlabel("Similitud")
        plt.ylabel("Documentos")
        st.pyplot(plt)
